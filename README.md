# ğŸ§  FastAPI LLM API

A simple, lightweight, and unrestricted FastAPI app that serves a large language model (LLM) using HuggingFace Transformers.

## ğŸš€ Features

- âš¡ FastAPI web server  
- ğŸ§  Transformer-based LLM inference  
- ğŸŒ Free deployment via Render.com  
- ğŸ”“ Uncensored and unrestricted usage  

## ğŸ› ï¸ Setup

1. Clone the repo:

```bash
git clone https://github.com/yourusername/llm-fastapi.git
cd llm-fastapi

2. Install dependencies:



pip install -r requirements.txt

3. Run locally:



uvicorn main:app --reload

ğŸ“¡ Deployment (Render.com)

Push this repository to GitHub

Create a new Web Service on Render

Connect your GitHub repo

Use start.sh as the start command

Done ğŸ‰


ğŸ§© API Usage

GET /: Health check

POST /generate: Send JSON with a prompt field to receive a model-generated response.


Example JSON payload:

{
  "prompt": "What is the capital of France?"
}

ğŸ“‚ File Structure

llm-fastapi/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ start.sh
â”œâ”€â”€ render.yaml
â””â”€â”€ README.md

ğŸ“ License

MIT License â€” free for personal or commercial use.

---

### To save and push this:

1. Create a file named `README.md` in your project folder:

```bash
nano README.md

2. Paste the above content into it.


3. Save and exit (Ctrl+O, Enter, Ctrl+X).


4. Commit and push:



git add README.md
git commit -m "Add README.md"
git push
